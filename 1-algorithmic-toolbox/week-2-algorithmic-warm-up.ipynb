{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1-1: Why study algorithms?](https://www.coursera.org/learn/algorithmic-toolbox/lecture/MAQjb/why-study-algorithms)\n",
    "- There are simple algorithms like linear scan, which you cannot really 'improve'. For these, you don't really have to think hard about.\n",
    "- Contrarily, you may face algorithms where you may not be sure about what to do: e.g. map, sorting, ...\n",
    "    - you could end up with very slow solutions\n",
    "    - there's a lot of room for optimizations\n",
    "    - improvements will influence greatly\n",
    "- You may also write a computer program to process natural language, which is very hard to tell computer to just 'do' the thing -- actually it's even hard to state what you want to acheieve with your program. \n",
    "    - but if you dig more into AI, solid basis of algorithms would be a very important asset\n",
    "- Throughout this class, we are going to try on the problems we could clearly state what program we are making, but still a bit challenging to solve. \n",
    "\n",
    "# [1-2: Coming up](https://www.coursera.org/learn/algorithmic-toolbox/lecture/nZTDh/coming-up)\n",
    "- For the next 2 lectures, we are going to look into:\n",
    "    - Fibonacci numbers\n",
    "    - Greatest common divisors \n",
    "- Why are we looking into these topics? \n",
    "   - They can show you why good algorithms are really important \n",
    "- Both algorithms work pretty straightforward. \n",
    "    - But the straightforward algorithm would take a very long time. So you would need a better solution, and as it turns out, there is. And we are going to find that out. \n",
    "    \n",
    "# [2-1: Fibonacci numbers](https://www.coursera.org/learn/algorithmic-toolbox/lecture/uoGuB/problem-overview)\n",
    "- Fibonacci number's definition\n",
    "![Definition of Fibonacci number](files/1.PNG)\n",
    "- It was created to study rabbit populations (because it kind of follows Fibonnaci number's rule)\n",
    "- Well, and rabbit populations grow quickly, and Fibonacci numbers actually do. \n",
    "![Rapid growth](files/2.PNG)\n",
    "- For example, \n",
    "```\n",
    "F(50) = 12586269025\n",
    "F(500) = 139423224561697880139724382870....\n",
    "```    \n",
    "- So, the problem we are going to look at is: How we can compute Fibonacci numbers. \n",
    "![Computing fibonacci condition](files/3.PNG)\n",
    "\n",
    "# [2-2: Naive algorithm](https://www.coursera.org/learn/algorithmic-toolbox/lecture/6AZzU/naive-algorithm)\n",
    "- The most naive algorithm would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FibRecurs(n):\n",
    "    if n <= 1: \n",
    "        return n\n",
    "    else:\n",
    "        return FibRecurs(n - 1) + FibRecurs(n - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a standard of measurement, if you take `T(n)` for the number of lines of code used:\n",
    "    - if n = 2, `T(2) = 3 + T(n - 1) + T(n - 2)` (taking account of recursive calls)\n",
    "    ```py\n",
    "    def FibRecurs(n = 2):\n",
    "        if n <= 1: # 1\n",
    "            return n \n",
    "        else: # 2\n",
    "            return FibRecurs(n - 1) + FibRecurs(n - 2) # 3\n",
    "    ```\n",
    "    - and with a little inspection, we can easily find that `T(n) >= Fibonacci(n)`. This means the lines of code needed for this naive algorithm would greatly increase for a big n. e.g. `T(100) = 1.77 * 10^21`\n",
    "    - this would take 5600 years at 1GHz!\n",
    "- Why so slow?\n",
    "    - This function makes a big tree of recursive calls -- basically you would need to compute something that is also in a fibonacci sequence.\n",
    "![Tree](files/4.PNG)\n",
    "    - Look into this. We are computing F(n-3) three times, which is useless.\n",
    "    - As you could expect, as the tree goes down, you would need to make more repeating calls with the same parameter to the function F.\n",
    "    - Essentially you are computing the same thing over and over incrementally, which makes it really slow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2-3: Efficient algorithm](https://www.coursera.org/learn/algorithmic-toolbox/lecture/Rj74z/efficient-algorithm)\n",
    "- Last time, the algorithm was very slow\n",
    "- Here's a simpler suggestion:\n",
    "```py\n",
    "create an array F[0...n]:\n",
    "F[0] = 0\n",
    "F[1] = 1\n",
    "for i from 2 to n:\n",
    "    F[i] = F[i - 1] + F[i - 2]\n",
    "return F[n]\n",
    "```\n",
    "- This has `T(n) = 2n + 2` so `T(100) = 202`. It's much, much faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3-1: Intro: Greatest Common Divisors I](https://www.coursera.org/learn/algorithmic-toolbox/lecture/vNEfl/problem-overview-and-naive-algorithm)\n",
    "\n",
    "## Definition of greatest common divisors\n",
    "- For integers `a` and `b`, the greatest common divisor `gcd(a,b)` is the largest integer `d` so that `d` divides both `a` and `b`.\n",
    "- It turns out it's relevant in many areas like cryptography. \n",
    "\n",
    "## Computation \n",
    "- Needs to run on large numbers like n > 3000000 or 100000000\n",
    "```\n",
    "input: integers a,b >=0\n",
    "output: gcd(a,b)\n",
    "```\n",
    "\n",
    "## Naive algorithm\n",
    "- Just compute everything from the beginning to the end, and return the largest divisor. \n",
    "![gcd naive](files/6.PNG)\n",
    "- This burdens your program to run a + b times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3-2: Intro: Greatest Common Divisors II](https://www.coursera.org/learn/algorithmic-toolbox/lecture/hODUL/efficient-algorithm)\n",
    "- One lemma is a key to the better algorithm:\n",
    "![key lemma](files/7.PNG)\n",
    "- Simple proof for this:\n",
    "![proof](files/8.PNG)\n",
    "- Euclidean algorithm would be much more efficient\n",
    "![euclidean algorithm](files/9.PNG)\n",
    "- It turns out as you try on big numbers, the algorithm is much simpler. \n",
    "- Each step reduces the size of numbers by about a factor of 2\n",
    "    - it takes `log(ab)` steps\n",
    "    - each step only takes a single division\n",
    "- Better algorithm comes with something interesting about the problem! You would need to know this for other problems as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4-1 Computing runtimes](https://www.coursera.org/learn/algorithmic-toolbox/lecture/jdaGN/computing-runtimes)\n",
    "- Until now we have only been counting lines of code as a measurement of complexity of algorithm. The number of lines would not of course correctly reflect the runtime of program. There should be a better measurement. \n",
    "- Things get dirty to calculate the actual time the program runs:\n",
    "    - The machine's hardware\n",
    "    - Compiler in use\n",
    "    - Optimizations performed\n",
    "    - Memory hierarchy\n",
    "    - You've got no idea where your program will run on\n",
    "- So it's really hard to figure out all of these. And there is an alternative, coming in the next clip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4-2 Asymptotic notation](https://www.coursera.org/learn/algorithmic-toolbox/lecture/zI8dH/asymptotic-notation)\n",
    "- The fundamental concept is that everything runs by a multiple of ca constant. \n",
    "- We could just ignore this constant multiple. But the problem comes: \n",
    "    - 1 day and 1 year also differ by just a constant multiple. But you cannot tell a difference if you ignore the constant multiple. \n",
    "- The workaround for this is:\n",
    "    - Asymptotic runtime: it loooks into how the runtime scales with input size.\n",
    "    - The runtime of `n^2` would of course be worse than any constant multiple like `3n`.\n",
    "    - The asymptotic behaviour differs a lot when you stretch it out on a graph:\n",
    "    ![graph](https://i.stack.imgur.com/WcBRI.png)\n",
    "    - As `x` becomes bigger, the difference between graphs get tremendous. That's why we don't really care about constants. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4-3 Big-O Notation](https://www.coursera.org/learn/algorithmic-toolbox/lecture/j5bev/big-o-notation)\n",
    "- `f(n) = O(g(n))` (pronounced f(n) is Big-O of g(n))\n",
    "    - this just means that `f` is bounded above by some constant multiple `c` of `g`.\n",
    "![big o example](files/10.PNG)\n",
    "    - example is given above. As you see, with `n^2`, you can make `3n^2 + 5n^2 + 2n^2` which is bigger or equal to LHS.\n",
    "    - actually the growth rate of `g` and `f` in the example differ by not by more than the factor of 3.\n",
    "    \n",
    "## Big O advantages\n",
    "1. Clarifies growth rate\n",
    "2. Cleans up notation (We can write O(n²), instead of 3n² + 5n + 2, and for example, for log, you don't need to specify base beacuse it is also considered a factor)\n",
    "3. Makes the algebra easier & simpler\n",
    "4. Cleans up all the dirty things dependent on conditions like the speed of a computer or memory hierarchy. \n",
    "\n",
    "## Big O warnings\n",
    "1. Factor in reality is important (a factor of 100 is big!)\n",
    "2. Big O is only asymptotic. It only tells you what happens when you put in really big inputs into the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4-4 Using Big-O](https://www.coursera.org/learn/algorithmic-toolbox/lecture/Zclml/using-big-o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
